{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install monai\n",
    "# !pip install torchvision\n",
    "# !pip install -U Setuptools\n",
    "# !pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "# !pip install adabelief-pytorch==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipywidgets widgetsnbextension\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練 ECA-NFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import setuptools\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader #只有dataloader用torch的\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AddChanneld,\n",
    "    AsDiscrete,\n",
    "    Compose,  \n",
    "    LoadImaged,\n",
    "    RandRotate90d,\n",
    "    ScaleIntensityd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    AsChannelFirstd,\n",
    "    Resized,\n",
    "    SaveImage,\n",
    "    Resize,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monai 狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Data folder\n",
    "> 設定大資料夾的位置，裡頭需含有`Train_Images`與`Train_Annotations_png`兩資料夾\n",
    "\n",
    "```\n",
    "SEG_Train_Datasets\n",
    "        |-> Train_Images\n",
    "        |-> Train_Annotations_png\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Data folder\n",
    "data_path = './SEG_Train_Datasets/'\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train files\n",
    "> 將一張image對應一張mask，並且用dictionary包起來，最後再用一個list將所有組包起來，並且藉由list indice將Training Data與Validation Data分出來"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_test = 237\n",
    "\n",
    "\n",
    "tempdir = data_path + \"Train_Images\"\n",
    "train_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "tempdir = data_path + \"Train_Annotations_png\"\n",
    "train_segs = sorted(glob.glob(os.path.join(tempdir, \"*.png\")))\n",
    "\n",
    "# Training data\n",
    "train_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[for_test:], train_segs[for_test:])]\n",
    "print(f\" {len(train_images[for_test:])} train_images and {len(train_segs[for_test:])} train_segs\")\n",
    "\n",
    "# validation data\n",
    "val_files = [{\"img\": img, \"seg\": seg} for img, seg in zip(train_images[:for_test], train_segs[:for_test])]\n",
    "print(f\" {len(train_images[:for_test])} val_images and {len(train_segs[:for_test])} val_segs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Trasform for image and segmentation\n",
    "> 製作transforms，注意有些是作用在image與mask上，但有些只作用在image\n",
    "\n",
    "### 特別附註\n",
    "```\n",
    "Monai的Resize、Resized，為作用於input的第三與第四維，代表你的圖片必須要是三維的，否則會出錯\n",
    "正確input : \n",
    "    (1, 1, 1716, 942)  --> Resize 800x800 --> (1, 1, 800, 800)\n",
    "\n",
    "錯誤input :\n",
    "    (1, 1716, 942)  --> Resize 800x800 --> (1, 1716, 800, 800)  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=[800, 800]),\n",
    "        RandRotate90d(keys=[\"img\", \"seg\"], prob=0.3, spatial_axes=[0, 1]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DataLoader for train and validation data\n",
    "> 重要參數 `batch_size`，需依照自己的GPU記憶體大小設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size\n",
    "batch_size = 24\n",
    "# create a training data loader\n",
    "train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size= batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size= batch_size, collate_fn=list_data_collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define metric and post-processing\n",
    "> 設定DiceMetric，與output用的transform，這部分則使用老師的example code中所寫的內容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "#output transform\n",
    "post_trans = Compose([EnsureType(), Activations(sigmoid=True), AsDiscrete(threshold=0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set environment\n",
    "> 設定GPU數量，以及啟用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0, 1, 2, 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Visualize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image, cmap= 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built Model\n",
    "\n",
    "> Decoder : DeepLabV3Plus\n",
    ">\n",
    "> Encoder : tu-eca_nfnet_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用來設定模型存檔的名稱\n",
    "encode_name = 'tu-eca_nfnet_l2_DeepLabV3Plus_origin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_params=dict(\n",
    "    pooling='avg',             # one of 'avg', 'max'\n",
    "    dropout=0.4,               # dropout ratio, default is None\n",
    "    activation=None,           # activation function, default is None\n",
    "    classes=1,                 # define number of output labels\n",
    ")\n",
    "\n",
    "\n",
    "encodes = 'tu-eca_nfnet_l2'\n",
    "model_no = smp.DeepLabV3Plus(encodes, aux_params=aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  因為此為多GPU運算，所以必須使用`torch.nn`的`DataParallel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.DataParallel(model_no).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "from adabelief_pytorch import AdaBelief\n",
    "optimizer = AdaBelief(model.parameters(), lr=1e-4, eps=1e-16, betas=(0.9, 0.99), weight_decouple = True, rectify = False, weight_decay = 1e-4)\n",
    "loss_function = monai.losses.DiceLoss(sigmoid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正式訓練\n",
    "> 這部分是使用老師提供的example下去微調，微調部分如總epoch、存模型的路徑等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### start a typical PyTorch training\n",
    "total_epochs = 500\n",
    "val_interval = 1\n",
    "best_metric = 100   #存best metric\n",
    "best_metric_epoch = -1  #存best epoch\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()  \n",
    "train_loss = []\n",
    "test_loss = []\n",
    "lr_set  = []\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{total_epochs}\")\n",
    "\n",
    "    # 開起訓練模式\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "\n",
    "    #計時\n",
    "    time_start = time.time()\n",
    "\n",
    "    for toto, batch_data in enumerate(train_loader):\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # 訓練過程\n",
    "        time_end = time.time()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size   #多少epoch\n",
    "        print(f\"on {step}/{epoch_len} GOGOGO   Use {'%.3f'%(time_end - time_start)}s   ||{'='*step+'>'+'-'*(epoch_len-step)}||\" , end='\\r')\n",
    "\n",
    "\n",
    "        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "        optimizer.zero_grad()    \n",
    "        outputs, label = model(inputs) #forward    \n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += float(loss.item())\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "\n",
    "    epoch_loss /= step\n",
    "    train_loss.append(epoch_loss)\n",
    "    local_time = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())    \n",
    "    print(\"\\n\", f\"{local_time} epoch {epoch + 1} training average loss: {epoch_loss:.4f}\") \n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            steps = 0\n",
    "            loss_val = 0\n",
    "\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                \n",
    "                val_outputs, val_out_label = model(val_images) #forward\n",
    "                val_outputs = Resize([-1, 1716, 942])(val_outputs)\n",
    "\n",
    "                val_loss = monai.losses.DiceLoss(sigmoid=True)(val_outputs, val_labels)\n",
    "                loss_val += float(val_loss)\n",
    "\n",
    "\n",
    "                #output transform\n",
    "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "\n",
    "                if  steps == 3 or steps == 5:\n",
    "                    print(\"val loss\", val_loss)\n",
    "                    visualize( \n",
    "                        image=val_images[0].cpu().permute(1,2,0), \n",
    "                        ground_truth_mask=val_labels[0].cpu().permute(1,2,0), \n",
    "                        predicted_mask=val_outputs[0].cpu().permute(1,2,0)\n",
    "\n",
    "                    )  \n",
    "                steps += 1\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            print(\"val_loss = \", loss_val / steps)\n",
    "            val_loss_ave = loss_val / steps\n",
    "\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "            metric_values.append(val_loss_ave)\n",
    "            test_loss.append(val_loss_ave)\n",
    "\n",
    "            if val_loss_ave < best_metric:\n",
    "                best_metric = val_loss_ave\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), f\"{encode_name}.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current val mean dice loss: {:.4f} best val mean dice loss: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, val_loss_ave, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            \n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize= (16, 8))\n",
    "ax.plot(np.arange(0, len(train_loss), 1), train_loss, label= 'train_loss', linewidth= 3)\n",
    "\n",
    "ax.plot(np.arange(0, len(test_loss), 1), test_loss, label= 'test_loss', linewidth= 3)\n",
    "ax.set_title(f'[{model.__class__.__name__} + {encode_name}_{ver}] Train_Test_loss')\n",
    "ax.set_ylabel('Loss', fontsize= 18)\n",
    "plt.legend()\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "ax1.plot(np.arange(0, len(lr_set), 1), lr_set, label= 'Learning Rate', c= 'black', linestyle= '--')\n",
    "ax1.set_ylabel('Learning Rate', fontsize= 18)\n",
    "ax.set_xlabel('epochs', fontsize= 18)\n",
    "\n",
    "bbox = dict(boxstyle=\"round\", fc=\"0.9\")\n",
    "\n",
    "plt.legend(loc= 'upper left')\n",
    "\n",
    "\n",
    "plt.text(0.5, 0.935, 'best epochs %d, val_loss= %.4f'%(best_metric_epoch, best_metric), transform=ax.transAxes, bbox= bbox, fontsize= 18)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f'{model.__class__.__name__} + {encode_name}_{ver}_Train_Test_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model並重現Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"{encode_name}.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "dice_metric.reset()\n",
    "with torch.no_grad():\n",
    "    val_images = None\n",
    "    val_labels = None\n",
    "    val_outputs = None\n",
    "    for val_data in val_loader:\n",
    "        val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "\n",
    "        val_outputs, val_out_label = model(val_images) #forward\n",
    "        val_outputs = Resize([-1, 1716, 942])(val_outputs)\n",
    "        val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]                \n",
    "\n",
    "        # compute metric for current iteration\n",
    "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "        print(dice_metric.aggregate())\n",
    "        \n",
    "    # aggregate the final mean dice result\n",
    "    metric = dice_metric.aggregate().item()\n",
    "    print(\"metric = \", metric)\n",
    "    # reset the status for next validation round\n",
    "    dice_metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = \"./Public_Image/\"\n",
    "test_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "print(f\" {len(test_images)} test_images\")\n",
    "\n",
    "test_files = [{\"img\": img} for img in test_images[:]]\n",
    "test_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"]),   \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\"])\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data=test_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1,  collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pub_data = sorted(glob.glob(tempdir + \"*.jpg\"))\n",
    "Pub_data[0].split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        test_images = test_data[\"img\"].to(device)\n",
    "\n",
    "        test_outputs, test_out_label = model(test_images) #forward\n",
    "        test_outputs = Resize([-1, 1716, 942])(test_outputs)\n",
    "        \n",
    "        saverPD = SaveImage(output_dir=f\"./Predict\", output_ext=\".png\", output_postfix=f\"{Pub_data[i].split('/')[-1].split('.')[0]}\",scale=255,separate_folder=False)\n",
    "        saverPD(test_outputs[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Private Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdir = \"./Pravite_Image1/\"\n",
    "private_images = sorted(glob.glob(os.path.join(tempdir, \"*.jpg\")))\n",
    "\n",
    "\n",
    "print(f\" {len(private_images)} private_images\")\n",
    "\n",
    "private_files = [{\"img\": img} for img in private_images[:]]\n",
    "private_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"]),\n",
    "        \n",
    "#         AddChanneld(keys=[\"seg\"]),        \n",
    "        AsChannelFirstd(keys=[\"img\"]),\n",
    "\n",
    "        ScaleIntensityd(keys=[\"img\"]),\n",
    "        Resized(keys=[\"img\"], spatial_size=[800, 800]),\n",
    "        EnsureTyped(keys=[\"img\"])\n",
    "    ]\n",
    ")\n",
    "test_ds = monai.data.Dataset(data= private_files, transform=test_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1,  collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pri_data = sorted(glob.glob(tempdir + \"*.jpg\"))\n",
    "Pri_data[0].split(\"/\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "        test_images = test_data[\"img\"].to(device)\n",
    "\n",
    "        test_outputs, test_out_label = model(test_images) #forward\n",
    "        test_outputs = Resize([-1, 1716, 942])(test_outputs)\n",
    "\n",
    "        saverPD = SaveImage(output_dir=f\"./Predict\", output_ext=\".png\", output_postfix=f\"{Pri_data[i].split('/')[-1].split('.')[0]}\",scale=255,separate_folder=False)\n",
    "        saverPD(test_outputs[0].cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 改檔名\n",
    "\n",
    "> 改成官方所需格式`Public_00000000.jpg`、`Private_00000000.jpg` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Predict = sorted(glob.glob(f\"./Predict/*.png\"))\n",
    "print(len(Predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in Predict:\n",
    "    os.rename(pred, os.path.join(*pred.split(\"/\")[:-1], pred.split(\"/\")[-1].split(\"_\", 1)[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
